{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d1b46e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.optim as optim \n",
    "import torchvision \n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader \n",
    "import torchvision.transforms as transforms \n",
    "from torch.utils.tensorboard import SummaryWriter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "153a95fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self,img_dim):\n",
    "        super().__init__()\n",
    "        self.disc = nn.Sequential(\n",
    "            nn.Linear(img_dim, 128),\n",
    "            nn.LeakyReLU(0.1),               #in gans leakyReLU is good default choice\n",
    "            nn.Linear(128,1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self,x):\n",
    "        return self.disc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae59f30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, z_dim,img_dim):       #z_dim is dim of latent noise that teh gen will be taking\n",
    "        super().__init__()\n",
    "        self.gen = nn.Sequential(\n",
    "            nn.Linear(z_dim, 256),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Linear(256, img_dim),\n",
    "            nn.Tanh(),                           #i/p normalized betwn 1 and -1 so do same for this too\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.gen(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4bf7791f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:56: SyntaxWarning: invalid escape sequence '\\ '\n",
      "<>:56: SyntaxWarning: invalid escape sequence '\\ '\n",
      "/tmp/ipykernel_17890/262435997.py:56: SyntaxWarning: invalid escape sequence '\\ '\n",
      "  f\"Epoch [{epoch}/{num_epochs}]\\ \"\n",
      "/tmp/ipykernel_17890/262435997.py:56: SyntaxWarning: invalid escape sequence '\\ '\n",
      "  f\"Epoch [{epoch}/{num_epochs}]\\ \"\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Compose' object has no attribute 'Compose'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     12\u001b[39m gen = Generator(z_dim, img_dim).to(device)\n\u001b[32m     13\u001b[39m fixed_noise = torch.randn((batch_size,z_dim)).to(device)\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m transform = \u001b[43mtransforms\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompose\u001b[49m(\n\u001b[32m     15\u001b[39m     [\n\u001b[32m     16\u001b[39m         transforms.ToTensor(), \n\u001b[32m     17\u001b[39m         transforms.Normalize((\u001b[32m0.1307\u001b[39m,),(\u001b[32m0.3081\u001b[39m,))]\n\u001b[32m     18\u001b[39m )\n\u001b[32m     19\u001b[39m dataset = datasets.MNIST(root=\u001b[33m'\u001b[39m\u001b[33mdataset/\u001b[39m\u001b[33m'\u001b[39m, transform= transform, download= \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     20\u001b[39m loader = DataLoader(dataset, batch_size= batch_size, shuffle = \u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[31mAttributeError\u001b[39m: 'Compose' object has no attribute 'Compose'"
     ]
    }
   ],
   "source": [
    "#hyperparameters etc.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\" \n",
    "lr = 1e-4 # andrej kar tweet this is best lr for adamopt\n",
    "# lr = 3e-4 # andrej kar tweet this is best lr for adamopt\n",
    "z_dim = 64 #128,256 #gans are sensitive to these hyperparameters\n",
    "#newer papers have better wasys to stabalizing gans \n",
    "img_dim  = 28*28*1\n",
    "batch_size = 32\n",
    "num_epochs = 50\n",
    "\n",
    "disc = Discriminator(img_dim).to(device)  #yeha ewta chuter tanab ??\n",
    "gen = Generator(z_dim, img_dim).to(device)\n",
    "fixed_noise = torch.randn((batch_size,z_dim)).to(device)\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(), \n",
    "        transforms.Normalize((0.1307,),(0.3081,))]\n",
    ")\n",
    "dataset = datasets.MNIST(root='dataset/', transform= transform, download= True)\n",
    "loader = DataLoader(dataset, batch_size= batch_size, shuffle = True)\n",
    "opt_disc = optim.Adam(disc.parameters(), lr= lr)\n",
    "opt_gen = optim.Adam(gen.parameters(), lr = lr)\n",
    "criterion = nn.BCELoss()  #similar form to previous intro gan equation \n",
    "writer_fake = SummaryWriter(f\"runs/GAN_MNIST/fake\")\n",
    "writer_real = SummaryWriter(f\"runs/GAN_MNIST/real\")        #confused about this separate video for tensorboard\n",
    "step = 0 #step for tensorboard\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for batch_idx, (real,_) in enumerate(loader):  #gans are unsupervised in a way that you dont need label for each image just real or fake\n",
    "        real = real.view(-1, 784).to(device) #-1 to keep number of examples in a batch\n",
    "        batch_size = real.shape[0]\n",
    "        \n",
    "        ## train discriminator : max log(D(real))+log(1-D(G(z)))\n",
    "        noise = torch.randn(batch_size,z_dim).to(device)\n",
    "        fake = gen(noise)\n",
    "        disc_real = disc(real).view(-1)   #faltten everything \n",
    "        lossD_real = criterion(disc_real, torch.ones_like(disc_real))  # derived using the bce los fxn pytorch documentation \n",
    "        ##here bce minimizes the -ve of the log(D(real)) which is ultimate way of formulating maximization of the +ve exp\n",
    "        disc_fake = disc(fake).view(-1)   #fake.detach() can be done to detach fake \n",
    "        lossD_fake = criterion(disc_fake, torch.zeors_like(disc_fake))\n",
    "        lossD = (lossD_fake+lossD_real)/2\n",
    "        disc.zero_grad()\n",
    "        lossD.backward(retain_graph = True)   #when we do .backward() allthe forward pass we generate will be remove form the cache\n",
    "        opt_disc.step()\n",
    "        \n",
    "\n",
    "        ## train generator min log(1-D(G(z))) <----> max  log(D(G(z)))\n",
    "        output = disc(fake).view(-1)  # to compute actual gradients we need intermediate grads from these fakes\n",
    "        lossG = criterion(output, torch.ones_like(output))\n",
    "        gen.zero_grad()\n",
    "        lossG.backward()\n",
    "        opt_gen.step()\n",
    "        \n",
    "        if batch_idx == 0:\n",
    "            print(\n",
    "                f\"Epoch [{epoch}/{num_epochs}]\\ \"\n",
    "                f\"Loss D: {lossD:.4f}, Loss G: {lossG:.4f}\"\n",
    "            )\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                fake = gen(fixed_noise).reshape(-1,1,28,28)\n",
    "                data = real.reshape(-1,1,28,28)\n",
    "                img_grid_fake = torchvision.utils.make_grid(fake, normalize = True)\n",
    "                img_grid_real = torchvision.utils.make_grid(data,normalize=True)\n",
    "                \n",
    "                writer_fake.add_image(\n",
    "                    \"Mnists Fake images\", img_grid_fake, global_step= step\n",
    "                )\n",
    "                \n",
    "                writer_real.add_image(\n",
    "                    \"Mnist real Images\", img_grid_real, global_step = step\n",
    "                )\n",
    "                step += 1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290db9dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0196f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
